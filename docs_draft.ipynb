{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ecg\n",
    "\n",
    "```ecg``` is a library that works with electrocardiogram signal. It allows easily load and process ecg signal and learn any model. The library is based on [Dataset]() and supports its whole functionality. So you can define your oun pipeline, write custon preprocess functions or use built-in ones and handle with datasets even if it does not fit into memory.\n",
    "\n",
    "```ecg``` has two modules: [```batch```]() and [```models```](). \n",
    "\n",
    "In ```batch``` we gather everything you may need to process ecg signal:\n",
    "* load and save signal in a number of formats\n",
    "* resample, crop or flip signal\n",
    "* filter signal\n",
    "* apply complex transformations like fft or wavelets\n",
    "* ...\n",
    "\n",
    "In ```models``` we provide several models that should inspire you to start you own research. Provided models are created to learn the most important problems in ecg:\n",
    "* how to recognize specific features of ecg like R-peaks, P-wave, T-wave\n",
    "* how to recignize dengerous deseases from ecg, for example - atrial fibrillation.\n",
    "\n",
    "# Basic usage\n",
    "\n",
    "Here is an example of pipeline that loads ecg signals, make some preprocessing and learns model over 50 epochs.\n",
    "```python\n",
    "model_train_pipeline = (ds.Pipeline()\n",
    "                        .load(fmt=\"wfdb\", components=[\"signal\", \"meta\"])\n",
    "                        .load(src=\".../data/REFERENCE.csv\", fmt=\"csv\", components=\"target\")\n",
    "                        .drop_labels([\"~\"])\n",
    "                        .replace_labels({\"N\": \"NO\", \"O\": \"NO\"})\n",
    "                        .random_resample_signals(\"normal\", loc=300, scale=10)\n",
    "                        .drop_short_signals(3000)\n",
    "                        .segment_signals(3000, 1000)\n",
    "                        .binarize_labels()\n",
    "                        .train_on_batch('my_ecg_model', metrics=f1_score, average='macro')\n",
    "                        .run(batch_size=300, shuffle=True, n_epochs=50, prefetch=0))\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Batch\n",
    "\n",
    "## ecg_batch\n",
    "This is a base class that defines how to store ecg data and lists all the actions that can be applied to ecg regardless of models. Class ```ecg_base``` has the following attributes:\n",
    "* ```signal``` stores ecg signal as numpy array\n",
    "* ```annotation```, this can be any array that annotate specific points of ecg signal, e.g. R peaks\n",
    "* ```meta``` contains any parameters of ecg signal, e.g. signal frequency\n",
    "* ```target``` contains label assigned to ecg\n",
    "* ```unique_labels``` is just a list of all possible target labels.\n",
    "\n",
    "## Actions of ecg_batch\n",
    "\n",
    "### ```load(self, src=None, fmt=None, components=None, *args, **kwargs)```\n",
    "\n",
    "### ```drop_labels(self, drop_list)```\n",
    "\n",
    "### ```keep_labels(self, keep_list)```\n",
    "\n",
    "### ```replace_labels(self, replace_dict)```\n",
    "\n",
    "### ```binarize_labels```\n",
    "\n",
    "### ```drop_short_signals(self, min_length, axis=-1)```\n",
    "\n",
    "### ```segment_signals(self, index, length, step, pad_value=0)```\n",
    "\n",
    "### ```random_segment_signals(self, index, length, n_segments, pad_value=0)```\n",
    "\n",
    "### ```convolve_signals(self, kernel, padding_mode=\"edge\", axis=-1, **kwargs)```\n",
    "\n",
    "### ```band_pass_signals(self, index, low=None, high=None, axis=-1)```\n",
    "\n",
    "\n",
    "## ecg_batch_tools\n",
    "\n",
    "Contains helpful functions that typically are called from some action of the ecg_batch for each signal separately. \n",
    "\n",
    "\n",
    "## kernels\n",
    "\n",
    "Contains kernel generation functions.\n",
    "\n",
    "## model_ecg_batch\n",
    "\n",
    "Contains actions that initialize models and common action for training, testing and predicting models.\n",
    "\n",
    "### ```fft_pretrained(pipeline, config=None)```\n",
    "Load pretrained [FFT]() model.\n",
    "\n",
    "### ```dirichlet_pretrained(pipeline, config=None)```\n",
    "Load pretrained [Dirichlet]() model.\n",
    "\n",
    "### ```train_on_batch(self, model_name, *args, **kwargs)```\n",
    "\n",
    "### ```test_on_batch(self, model_name, *args, **kwargs)```\n",
    "\n",
    "### ```predict_on_batch(self, model_name, *args, **kwargs)```\n",
    "\n",
    "## utils\n",
    "\n",
    "Miscellaneous ECG Batch utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models\n",
    "\n",
    "This is a place where ecg models live. You can write your own model or exploit provided models, however, any model should extend [base_model]() class. \n",
    "\n",
    "### Base_model\n",
    "All what you may need from model is the following methods:\n",
    "\n",
    "### ```load(self, *args, **kwargs)```\n",
    "Load model.\n",
    "\n",
    "### ```save(self, *args, **kwargs)```\n",
    "Save model.\n",
    "\n",
    "### ```train_on_batch(self, batch, *args, **kwargs)```\n",
    "Run a single gradient update on a single batch.\n",
    "        \n",
    "### ```test_on_batch(self, batch, *args, **kwargs)```\n",
    "Get model loss for a single batch.\n",
    "\n",
    "### ```predict_on_batch(self, batch, *args, **kwargs)```\n",
    "Get model predictions for a single batch.\n",
    "\n",
    "Once these methods are defined one can add them to pipeline.\n",
    "For example, train pipline looks like\n",
    "\n",
    "```python\n",
    "model_train_pipeline = (ds.Pipeline()\n",
    "                        .load(fmt=\"wfdb\", components=[\"signal\", \"meta\"])\n",
    "                        .load(src=\".../data/REFERENCE.csv\", fmt=\"csv\", components=\"target\")\n",
    "                        .do_some_preprocess()\n",
    "                        .train_on_batch('fft_inception', metrics=f1_score, average='macro')\n",
    "                        .run(batch_size=300, n_epochs=50))\n",
    "```\n",
    "\n",
    "Note that until now everything was independent on model backend.\n",
    "Below you can find a guide how to build a model with [Keras]() and [Tensorflow]()\n",
    "\n",
    "## How to build a model with Keras\n",
    "\n",
    "To build a model with Keras you only need to define a sequence of layers, everything else is implemented in [KerasBaseModel]().\n",
    "For example, let's build a simple FC model. \n",
    "```python\n",
    "from keras.layers import Input, Dense\n",
    "from keras.models import Model\n",
    "\n",
    "class SimpleFCModel(KerasBaseModel):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self._input_shape = None\n",
    "        \n",
    "        def build(self, input_shape):\n",
    "            '''\n",
    "            Build and compile conv model\n",
    "            '''\n",
    "            self._input_shape = input_shape\n",
    "            x = Input(self._input_shape)\n",
    "            out = Dense(16)(x)\n",
    "            self.model = Model(inputs=x, outputs=out)\n",
    "            self.model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\")\n",
    "            return self\n",
    "```\n",
    "SimpleFCModel is a [dynamic]() model, i.e. it is build and compiles at first time it gets batch. So we do not need specify the input shape in advance. The dynamic model gets is automatically from batch. To enable dynamic mode, the following declaration is required in [model_ecg_batch]():\n",
    "\n",
    "```python\n",
    "@ds.model(mode=\"dynamic\")\n",
    "def fc_model(batch, config=None):\n",
    "    '''\n",
    "    Define simple FC model model\n",
    "    '''\n",
    "    signal_shape = batch.signal[0].shape\n",
    "    return SimpleFCModel().build(signal_shape)\n",
    "```\n",
    "\n",
    "Now everything is ready to train:\n",
    "```python\n",
    "fc_train_pipeline = (ds.Pipeline()\n",
    "                       .load(fmt=\"wfdb\", components=[\"signal\", \"meta\"])\n",
    "                       .load(src=\".../data/REFERENCE.csv\", fmt=\"csv\", components=\"target\")\n",
    "                       .do_some_preprocess()\n",
    "                       .train_on_batch('fc_model')\n",
    "                       .run(batch_size=300, shuffle=True, drop_last=True, n_epochs=50))\n",
    "```\n",
    "and predict our model:\n",
    "```python\n",
    "config = {'path': \"/path_to_fc_model_dump\"}\n",
    "fc_predict_pipeline = (ds.Pipeline(config={'fc_model': config})\n",
    "                         .init_model('fc_model')\n",
    "                         .init_variable(\"prediction\", [])\n",
    "                         .load(fmt=\"wfdb\", components=[\"signal\", \"meta\"])\n",
    "                         .load(src=\".../data/REFERENCE.csv\", fmt=\"csv\", components=\"target\")\n",
    "                         .do_some_preprocess()\n",
    "                         .predict_on_batch('fc_model')\n",
    "                         .run(batch_size=100, shuffle=False, drop_last=False, n_epochs=1))\n",
    "```\n",
    "\n",
    "### KerasBaseModel\n",
    "Defines methods of BaseModel for Keras backend.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FFT inception model\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
